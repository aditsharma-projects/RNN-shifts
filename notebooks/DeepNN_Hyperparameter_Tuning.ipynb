{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "## Inputs\n",
    "The input variables for all trials in this notebook are the following:\n",
    "```py\n",
    "include_fields = ['day_of_week','hours_l1','hours_l2','hours_l3','hours_l4',\n",
    "                  'hours_l5','hours_l6','hours_l7','hours_l8','hours_l14','avg_employees',\n",
    "                  'perc_hours_today_before', 'perc_hours_yesterday_before', 'perc_hours_tomorrow_before']\n",
    "```\n",
    "\n",
    "## Models and Hyperparameters\n",
    "The following hyperparameters are explored using a grid search. \n",
    "```py\n",
    "Num_Layers = [2,4,6,8]\n",
    "Num_Units = [8,16,24,32]\n",
    "Dropout_Rate = [0.25,0.5,0.75]\n",
    "```\n",
    "Each combination of num_layers, num_units, and dropout_rate is trained on the train data and validated on the crossvalidation data. The outputted numbers in the cells below correspond to the crossvalidation loss and metric scores. \n",
    "\n",
    "For a given permuation {l,u,r} of {num_layers,num_units,dropout_rate}, a model contains (l-1) layers of width u, each with dropout rate r applied to its output, connected to a final layer that outputs a prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Train and Validation sets. Time taken: 243.99558639526367\n",
      "<bound method NDFrame.head of            hours  day_of_week  hours_l1  hours_l2  hours_l3  hours_l4  \\\n",
      "0            0.0            4       0.0      0.00       0.0      7.50   \n",
      "1            7.5            3       0.0      0.00       7.5      0.00   \n",
      "2            0.0            2       0.0      7.50       0.0      0.00   \n",
      "3            0.0            1       7.5      0.00       0.0      0.00   \n",
      "4            7.5            0       0.0      0.00       0.0      0.00   \n",
      "...          ...          ...       ...       ...       ...       ...   \n",
      "146318634    7.0            5       0.0      6.75       7.5      7.75   \n",
      "146318636    0.0            0       0.0     12.00       0.0      0.00   \n",
      "146318638    0.0            2       0.0      0.00       0.0     12.00   \n",
      "146318639    0.0            1       0.0      0.00      12.0      0.00   \n",
      "146318641    0.0            4       0.0      0.00       0.0      0.00   \n",
      "\n",
      "           hours_l5  hours_l6  hours_l7  hours_l8  hours_l14  avg_employees  \\\n",
      "0               7.5       0.0      0.00       0.0       0.00      56.857143   \n",
      "1               0.0       0.0      0.00       0.0       7.75      56.357143   \n",
      "2               0.0       0.0      0.00       0.0       0.00      56.785713   \n",
      "3               0.0       0.0      0.00       0.0       0.00      57.142857   \n",
      "4               0.0       0.0      0.00       0.0       7.75      57.500000   \n",
      "...             ...       ...       ...       ...        ...            ...   \n",
      "146318634       0.0       0.0      7.25       7.5       7.25      45.000000   \n",
      "146318636       0.0       0.0      0.00       0.0       0.00      44.571430   \n",
      "146318638       0.0       0.0      0.00       0.0       0.00      44.857143   \n",
      "146318639       0.0       0.0      0.00       0.0       0.00      44.714287   \n",
      "146318641       0.0      12.0      0.00       0.0       0.00      45.142857   \n",
      "\n",
      "           perc_hours_today_before  perc_hours_yesterday_before  \\\n",
      "0                             0.00                         0.00   \n",
      "1                             0.23                         0.00   \n",
      "2                             0.00                         0.06   \n",
      "3                             0.06                         0.28   \n",
      "4                             0.28                         0.20   \n",
      "...                            ...                          ...   \n",
      "146318634                     0.21                         0.15   \n",
      "146318636                     0.00                         0.00   \n",
      "146318638                     0.00                         0.00   \n",
      "146318639                     0.00                         0.00   \n",
      "146318641                     0.00                         0.00   \n",
      "\n",
      "           perc_hours_tomorrow_before  \n",
      "0                                0.00  \n",
      "1                                0.00  \n",
      "2                                0.23  \n",
      "3                                0.00  \n",
      "4                                0.06  \n",
      "...                               ...  \n",
      "146318634                        0.04  \n",
      "146318636                        0.00  \n",
      "146318638                        0.00  \n",
      "146318639                        0.00  \n",
      "146318641                        1.00  \n",
      "\n",
      "[137722552 rows x 15 columns]>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "include_fields = ['hours','day_of_week','hours_l1','hours_l2','hours_l3','hours_l4',\n",
    "                  'hours_l5','hours_l6','hours_l7','hours_l8','hours_l14','avg_employees',\n",
    "                  'perc_hours_today_before', 'perc_hours_yesterday_before', 'perc_hours_tomorrow_before']\n",
    "\n",
    "startTime = time.time()\n",
    "train = pd.read_csv(\"/export/storage_adgandhi/PBJhours_ML/Data/Intermediate/train_test_validation/training_set.csv\",usecols=include_fields).dropna()\n",
    "val = pd.read_csv(\"/export/storage_adgandhi/PBJhours_ML/Data/Intermediate/train_test_validation/crossvalidation_set.csv\",usecols=include_fields).dropna()\n",
    "print(f\"Loaded Train and Validation sets. Time taken: {time.time()-startTime}\")\n",
    "print(train.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_labels = train.drop(['hours'], axis=1), train.filter(['hours'])\n",
    "val_inputs, val_labels = val.drop(['hours'], axis=1), val.filter(['hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(137722552, 20)\n"
     ]
    }
   ],
   "source": [
    "#appends one hot expansion of selected labels to end of dataframe (axis 1)\n",
    "def expand_one_hot(labels,dataset):\n",
    "    outList = []\n",
    "    for label in labels:  \n",
    "        col = dataset[label]\n",
    "        ###Generate a dict for all unique values (Don't waste space encoding non important job id's)\n",
    "        map = {}\n",
    "        index = 0\n",
    "        for element in col.unique():\n",
    "            map[element] = index\n",
    "            index += 1\n",
    "        col = col.map(map)\n",
    "        tensor = tf.one_hot(col,len(col.unique()))\n",
    "        outList.append(tensor)\n",
    "        dataset = dataset.drop(columns=[label])\n",
    "    \n",
    "    outList.append(dataset)\n",
    "    output = tf.concat(outList,1)\n",
    "    return output\n",
    "\n",
    "train_inputs = expand_one_hot(['day_of_week'],train_inputs)\n",
    "val_inputs = expand_one_hot(['day_of_week'],val_inputs)\n",
    "\n",
    "print(train_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of devices: 1\n",
      "<BatchDataset shapes: ((None, 20), (None, 1)), types: (tf.float32, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "BUFFER_SIZE = 10000\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "BATCH_SIZE_PER_REPLICA = 512\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "trainSet = tf.data.Dataset.from_tensor_slices((train_inputs,train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "valSet = tf.data.Dataset.from_tensor_slices((val_inputs,val_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "print(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        #Build model to depth specificed in hparams[HP_NUM_LAYERS]\n",
    "        for i in range(hparams[HP_NUM_LAYERS]):\n",
    "            if i+1 == hparams[HP_NUM_LAYERS]:\n",
    "                model.add(tf.keras.layers.Dense(1))\n",
    "            elif i == 0:\n",
    "                model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu))\n",
    "            else:\n",
    "                model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "                model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu))           \n",
    "    \n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "        )\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss', min_delta=0.01, patience=1, verbose=0,\n",
    "                    mode='auto', baseline=None, restore_best_weights=False\n",
    "                )\n",
    "    \n",
    "    startTime = time.time()\n",
    "    model.fit(trainSet, epochs=10, verbose=0, validation_data=valSet, callbacks=[callback]) \n",
    "    _, accuracy = model.evaluate(valSet)\n",
    "    return accuracy, time.time()-startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy, time = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "        print(f\"MAE: {accuracy}    Time Taken: {time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8,16,24,32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.25, 0.5, 0.75]))\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([2,4,6,8]))\n",
    "\n",
    "METRIC_ACCURACY = 'Mean Squared Error'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_NUM_LAYERS],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Mean Squared Error')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 8, 'dropout': 0.25, 'num_layers': 2}\n",
      "134236/134236 [==============================] - 159s 1ms/step - loss: 13.3636 - mean_absolute_error: 2.9715\n",
      "MAE: 2.971541166305542    Time Taken: 1590.6408619880676 seconds\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.25, 'num_layers': 2}\n",
      "134236/134236 [==============================] - 150s 1ms/step - loss: 13.0874 - mean_absolute_error: 2.9143\n",
      "MAE: 2.9142937660217285    Time Taken: 2027.4406867027283 seconds\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 24, 'dropout': 0.25, 'num_layers': 2}\n",
      "134236/134236 [==============================] - 167s 1ms/step - loss: 13.1453 - mean_absolute_error: 2.9399\n",
      "MAE: 2.9398937225341797    Time Taken: 1107.9467117786407 seconds\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 32, 'dropout': 0.25, 'num_layers': 2}\n",
      "134236/134236 [==============================] - 148s 1ms/step - loss: 12.9790 - mean_absolute_error: 2.9139\n",
      "MAE: 2.9138858318328857    Time Taken: 1067.9047322273254 seconds\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 8, 'dropout': 0.25, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 160s 1ms/step - loss: 17.4393 - mean_absolute_error: 3.6051\n",
      "MAE: 3.6050760746002197    Time Taken: 1216.3100955486298 seconds\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 16, 'dropout': 0.25, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 157s 1ms/step - loss: 14.5604 - mean_absolute_error: 3.3202\n",
      "MAE: 3.320221185684204    Time Taken: 1765.823754310608 seconds\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 24, 'dropout': 0.25, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 158s 1ms/step - loss: 13.9022 - mean_absolute_error: 3.1661\n",
      "MAE: 3.166147470474243    Time Taken: 1221.4553463459015 seconds\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.25, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 160s 1ms/step - loss: 14.1753 - mean_absolute_error: 3.2400\n",
      "MAE: 3.2399632930755615    Time Taken: 1248.266485452652 seconds\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 8, 'dropout': 0.5, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 167s 1ms/step - loss: 16.3515 - mean_absolute_error: 3.5097\n",
      "MAE: 3.5097410678863525    Time Taken: 2385.8422679901123 seconds\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 16, 'dropout': 0.5, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 172s 1ms/step - loss: 15.8850 - mean_absolute_error: 3.5401\n",
      "MAE: 3.540116310119629    Time Taken: 2916.1793246269226 seconds\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 24, 'dropout': 0.5, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 169s 1ms/step - loss: 15.1610 - mean_absolute_error: 3.3552\n",
      "MAE: 3.355185031890869    Time Taken: 1376.019551038742 seconds\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 32, 'dropout': 0.5, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 166s 1ms/step - loss: 14.9380 - mean_absolute_error: 3.3399\n",
      "MAE: 3.3399407863616943    Time Taken: 1292.7485904693604 seconds\n",
      "--- Starting trial: run-12\n",
      "{'num_units': 8, 'dropout': 0.75, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 166s 1ms/step - loss: 21.3120 - mean_absolute_error: 3.6898\n",
      "MAE: 3.689797878265381    Time Taken: 1846.2616872787476 seconds\n",
      "--- Starting trial: run-13\n",
      "{'num_units': 16, 'dropout': 0.75, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 167s 1ms/step - loss: 19.1494 - mean_absolute_error: 3.8977\n",
      "MAE: 3.897665023803711    Time Taken: 2953.1394567489624 seconds\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 24, 'dropout': 0.75, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 168s 1ms/step - loss: 14.3999 - mean_absolute_error: 3.2077\n",
      "MAE: 3.2077200412750244    Time Taken: 1296.6928889751434 seconds\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 32, 'dropout': 0.75, 'num_layers': 4}\n",
      "134236/134236 [==============================] - 169s 1ms/step - loss: 14.6274 - mean_absolute_error: 3.2331\n",
      "MAE: 3.2331125736236572    Time Taken: 2413.906663417816 seconds\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 8, 'dropout': 0.25, 'num_layers': 6}\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for num_units in HP_NUM_UNITS.domain.values:\n",
    "            if int(num_layers)==2 and float(dropout_rate)!=0.25:\n",
    "                continue\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_LAYERS: num_layers,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-16\n",
      "{'num_units': 8, 'dropout': 0.2, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 170s 1ms/step - loss: 13.8119 - mean_absolute_error: 3.1440\n",
      "MAE: 3.144009590148926    Time Taken: 3140.2818489074707 seconds\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 16, 'dropout': 0.2, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 168s 1ms/step - loss: 13.4881 - mean_absolute_error: 3.0856\n",
      "MAE: 3.0855648517608643    Time Taken: 1805.8771080970764 seconds\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 24, 'dropout': 0.2, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 169s 1ms/step - loss: 13.2354 - mean_absolute_error: 3.0201\n",
      "MAE: 3.0200936794281006    Time Taken: 1800.3471038341522 seconds\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 32, 'dropout': 0.2, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 165s 1ms/step - loss: 13.2465 - mean_absolute_error: 3.0096\n",
      "MAE: 3.009599208831787    Time Taken: 1763.9263377189636 seconds\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 64, 'dropout': 0.2, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 169s 1ms/step - loss: 12.7870 - mean_absolute_error: 2.8957\n",
      "MAE: 2.895702838897705    Time Taken: 1243.4794852733612 seconds\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 8, 'dropout': 0.4, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 164s 1ms/step - loss: 17.0147 - mean_absolute_error: 3.4922\n",
      "MAE: 3.492199182510376    Time Taken: 1226.787061214447 seconds\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 16, 'dropout': 0.4, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 165s 1ms/step - loss: 14.4128 - mean_absolute_error: 3.3123\n",
      "MAE: 3.3123090267181396    Time Taken: 1732.9405970573425 seconds\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 24, 'dropout': 0.4, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 164s 1ms/step - loss: 14.7581 - mean_absolute_error: 3.3549\n",
      "MAE: 3.3548872470855713    Time Taken: 1740.44180393219 seconds\n",
      "--- Starting trial: run-24\n",
      "{'num_units': 32, 'dropout': 0.4, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 162s 1ms/step - loss: 14.4644 - mean_absolute_error: 3.2766\n",
      "MAE: 3.276561975479126    Time Taken: 1729.1325423717499 seconds\n",
      "--- Starting trial: run-25\n",
      "{'num_units': 64, 'dropout': 0.4, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 167s 1ms/step - loss: 13.6291 - mean_absolute_error: 3.1153\n",
      "MAE: 3.1153430938720703    Time Taken: 1736.196836233139 seconds\n",
      "--- Starting trial: run-26\n",
      "{'num_units': 8, 'dropout': 0.6, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 165s 1ms/step - loss: 24.7308 - mean_absolute_error: 4.0767\n",
      "MAE: 4.076712131500244    Time Taken: 1736.7362134456635 seconds\n",
      "--- Starting trial: run-27\n",
      "{'num_units': 16, 'dropout': 0.6, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 163s 1ms/step - loss: 20.3589 - mean_absolute_error: 3.7773\n",
      "MAE: 3.777252197265625    Time Taken: 2777.105506181717 seconds\n",
      "--- Starting trial: run-28\n",
      "{'num_units': 24, 'dropout': 0.6, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 193s 1ms/step - loss: 15.9131 - mean_absolute_error: 3.5292\n",
      "MAE: 3.529161214828491    Time Taken: 2302.0103282928467 seconds\n",
      "--- Starting trial: run-29\n",
      "{'num_units': 32, 'dropout': 0.6, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 187s 1ms/step - loss: 15.8703 - mean_absolute_error: 3.5686\n",
      "MAE: 3.568563938140869    Time Taken: 6219.704747200012 seconds\n",
      "--- Starting trial: run-30\n",
      "{'num_units': 64, 'dropout': 0.6, 'num_layers': 3}\n",
      "134236/134236 [==============================] - 186s 1ms/step - loss: 14.8386 - mean_absolute_error: 3.3602\n",
      "MAE: 3.360211133956909    Time Taken: 1990.8162314891815 seconds\n"
     ]
    }
   ],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8,16,24,32,64]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.2, 0.4, 0.6]))\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([3]))\n",
    "\n",
    "METRIC_ACCURACY = 'Mean Squared Error'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_NUM_LAYERS],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Mean Squared Error')],\n",
    "    )\n",
    "    \n",
    "session_num = 16\n",
    "for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for num_units in HP_NUM_UNITS.domain.values:\n",
    "            if int(num_layers)==2 and float(dropout_rate)!=0.25:\n",
    "                continue\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_LAYERS: num_layers,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
