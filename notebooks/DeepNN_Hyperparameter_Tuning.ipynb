{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "## Inputs\n",
    "The input variables for all trials in this notebook are the following:\n",
    "```py\n",
    "include_fields = ['day_of_week','hours_l1','hours_l2','hours_l3','hours_l4',\n",
    "                  'hours_l5','hours_l6','hours_l7','hours_l8','hours_l14','avg_employees',\n",
    "                  'perc_hours_today_before', 'perc_hours_yesterday_before', 'perc_hours_tomorrow_before']\n",
    "```\n",
    "\n",
    "## Models and Hyperparameters\n",
    "The following hyperparameters are explored using a grid search. \n",
    "```py\n",
    "Num_Layers = [2,4,6,8]\n",
    "Num_Units = [8,16,24,32]\n",
    "Dropout_Rate = [0.25,0.5,0.75]\n",
    "```\n",
    "Each combination of num_layers, num_units, and dropout_rate is trained on the train data and validated on the crossvalidation data. The outputted numbers in the cells below correspond to the crossvalidation loss and metric scores. \n",
    "\n",
    "For a given permuation {l,u,r} of {num_layers,num_units,dropout_rate}, a model contains (l-1) layers of width u, each with dropout rate r applied to its output, connected to a final layer that outputs a prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "include_fields = ['hours','day_of_week','hours_l1','hours_l2','hours_l3','hours_l4',\n",
    "                  'hours_l5','hours_l6','hours_l7','hours_l8','hours_l14','avg_employees',\n",
    "                  'perc_hours_today_before', 'perc_hours_yesterday_before', 'perc_hours_tomorrow_before']\n",
    "\n",
    "startTime = time.time()\n",
    "train = pd.read_csv(\"/export/storage_adgandhi/PBJhours_ML/Data/Intermediate/train_test_validation/training_set.csv\",usecols=include_fields).dropna()\n",
    "val = pd.read_csv(\"/export/storage_adgandhi/PBJhours_ML/Data/Intermediate/train_test_validation/crossvalidation_set.csv\",usecols=include_fields).dropna()\n",
    "print(f\"Loaded Train and Validation sets. Time taken: {time.time()-startTime}\")\n",
    "print(train.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_labels = train.drop(['hours'], axis=1), train.filter(['hours'])\n",
    "val_inputs, val_labels = val.drop(['hours'], axis=1), val.filter(['hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appends one hot expansion of selected labels to end of dataframe (axis 1)\n",
    "def expand_one_hot(labels,dataset):\n",
    "    outList = []\n",
    "    for label in labels:  \n",
    "        col = dataset[label]\n",
    "        ###Generate a dict for all unique values (Don't waste space encoding non important job id's)\n",
    "        map = {}\n",
    "        index = 0\n",
    "        for element in col.unique():\n",
    "            map[element] = index\n",
    "            index += 1\n",
    "        col = col.map(map)\n",
    "        tensor = tf.one_hot(col,len(col.unique()))\n",
    "        outList.append(tensor)\n",
    "        dataset = dataset.drop(columns=[label])\n",
    "    \n",
    "    outList.append(dataset)\n",
    "    output = tf.concat(outList,1)\n",
    "    return output\n",
    "\n",
    "train_inputs = expand_one_hot(['day_of_week'],train_inputs)\n",
    "val_inputs = expand_one_hot(['day_of_week'],val_inputs)\n",
    "\n",
    "print(train_inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "BUFFER_SIZE = 10000\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "BATCH_SIZE_PER_REPLICA = 512\n",
    "BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "trainSet = tf.data.Dataset.from_tensor_slices((train_inputs,train_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "valSet = tf.data.Dataset.from_tensor_slices((val_inputs,val_labels)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "\n",
    "print(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams):\n",
    "    with strategy.scope():\n",
    "        model = tf.keras.models.Sequential()\n",
    "\n",
    "        #Build model to depth specificed in hparams[HP_NUM_LAYERS]\n",
    "        for i in range(hparams[HP_NUM_LAYERS]):\n",
    "            if i+1 == hparams[HP_NUM_LAYERS]:\n",
    "                model.add(tf.keras.layers.Dense(1))\n",
    "            elif i == 0:\n",
    "                model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu))\n",
    "            else:\n",
    "                model.add(tf.keras.layers.Dropout(hparams[HP_DROPOUT]))\n",
    "                model.add(tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu))           \n",
    "    \n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.MeanSquaredError(),\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    "        )\n",
    "    \n",
    "    callback = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss', min_delta=0.01, patience=1, verbose=0,\n",
    "                    mode='auto', baseline=None, restore_best_weights=False\n",
    "                )\n",
    "    \n",
    "    startTime = time.time()\n",
    "    model.fit(trainSet, epochs=10, verbose=0, validation_data=valSet, callbacks=[callback]) \n",
    "    _, accuracy = model.evaluate(valSet)\n",
    "    return accuracy, time.time()-startTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "    with tf.summary.create_file_writer(run_dir).as_default():\n",
    "        hp.hparams(hparams)  # record the values used in this trial\n",
    "        accuracy, time = train_test_model(hparams)\n",
    "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)\n",
    "        print(f\"MAE: {accuracy}    Time Taken: {time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([8,16,24,32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.25, 0.5, 0.75]))\n",
    "HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([2,4,6,8]))\n",
    "\n",
    "METRIC_ACCURACY = 'Mean Squared Error'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_NUM_LAYERS],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Mean Squared Error')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 8, 'dropout': 0.25, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 587s 1ms/step - loss: 13.7086 - mean_absolute_error: 3.1174\n",
      "MAE: 3.1173713207244873    Time Taken: 4153.185551643372 seconds\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 16, 'dropout': 0.25, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 579s 1ms/step - loss: 13.6644 - mean_absolute_error: 3.0769\n",
      "MAE: 3.076856851577759    Time Taken: 4123.465849399567 seconds\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 24, 'dropout': 0.25, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 606s 1ms/step - loss: 13.5299 - mean_absolute_error: 3.0546\n",
      "MAE: 3.0546138286590576    Time Taken: 6057.240978717804 seconds\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 32, 'dropout': 0.25, 'num_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "session_num = 0\n",
    "for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for num_units in HP_NUM_UNITS.domain.values:\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_LAYERS: num_layers,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-3\n",
      "{'num_units': 32, 'dropout': 0.25, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 606s 1ms/step - loss: 13.4821 - mean_absolute_error: 3.0569\n",
      "MAE: 3.056939125061035    Time Taken: 6314.490927457809 seconds\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 8, 'dropout': 0.5, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 611s 1ms/step - loss: 14.2999 - mean_absolute_error: 3.2726\n",
      "MAE: 3.2726030349731445    Time Taken: 4357.095632314682 seconds\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 16, 'dropout': 0.5, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 611s 1ms/step - loss: 13.7397 - mean_absolute_error: 3.1449\n",
      "MAE: 3.1449296474456787    Time Taken: 6241.574224233627 seconds\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 24, 'dropout': 0.5, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 612s 1ms/step - loss: 13.7729 - mean_absolute_error: 3.1238\n",
      "MAE: 3.1237761974334717    Time Taken: 4366.5706615448 seconds\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 32, 'dropout': 0.5, 'num_layers': 2}\n",
      "536944/536944 [==============================] - 609s 1ms/step - loss: 13.5116 - mean_absolute_error: 3.0735\n",
      "MAE: 3.073488473892212    Time Taken: 4381.3382115364075 seconds\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 8, 'dropout': 0.75, 'num_layers': 2}\n"
     ]
    }
   ],
   "source": [
    "session_num = 3\n",
    "for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for num_units in HP_NUM_UNITS.domain.values:\n",
    "            if int(num_layers) == 2 and float(dropout_rate) == 0.25 and int(num_units) != 32:\n",
    "                continue\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_LAYERS: num_layers,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-13\n",
      "{'num_units': 8, 'dropout': 0.25, 'num_layers': 4}\n",
      "536944/536944 [==============================] - 627s 1ms/step - loss: 14.8297 - mean_absolute_error: 3.3363\n",
      "MAE: 3.336268186569214    Time Taken: 4778.473185777664 seconds\n",
      "--- Starting trial: run-14\n",
      "{'num_units': 16, 'dropout': 0.25, 'num_layers': 4}\n",
      "536944/536944 [==============================] - 626s 1ms/step - loss: 13.9795 - mean_absolute_error: 3.1706\n",
      "MAE: 3.170628070831299    Time Taken: 4801.904301166534 seconds\n",
      "--- Starting trial: run-15\n",
      "{'num_units': 24, 'dropout': 0.25, 'num_layers': 4}\n",
      "536944/536944 [==============================] - 619s 1ms/step - loss: 13.8331 - mean_absolute_error: 3.1596\n",
      "MAE: 3.15960955619812    Time Taken: 4869.2269151210785 seconds\n",
      "--- Starting trial: run-16\n",
      "{'num_units': 32, 'dropout': 0.25, 'num_layers': 4}\n",
      "536944/536944 [==============================] - 640s 1ms/step - loss: 13.3729 - mean_absolute_error: 3.0682\n",
      "MAE: 3.0681569576263428    Time Taken: 7339.327345371246 seconds\n",
      "--- Starting trial: run-17\n",
      "{'num_units': 8, 'dropout': 0.5, 'num_layers': 4}\n",
      "536944/536944 [==============================] - 608s 1ms/step - loss: 15.0761 - mean_absolute_error: 3.3871\n",
      "MAE: 3.387101173400879    Time Taken: 7535.112235069275 seconds\n",
      "--- Starting trial: run-18\n",
      "{'num_units': 16, 'dropout': 0.5, 'num_layers': 4}\n"
     ]
    }
   ],
   "source": [
    "session_num = 13\n",
    "for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for num_units in HP_NUM_UNITS.domain.values:\n",
    "            if int(num_layers) == 2:\n",
    "                continue\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_LAYERS: num_layers,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-18\n",
      "{'num_units': 16, 'dropout': 0.5, 'num_layers': 4}\n",
      "268472/268472 [==============================] - 307s 1ms/step - loss: 14.0474 - mean_absolute_error: 3.1686\n",
      "MAE: 3.168642520904541    Time Taken: 2478.577969312668 seconds\n",
      "--- Starting trial: run-19\n",
      "{'num_units': 24, 'dropout': 0.5, 'num_layers': 4}\n",
      "268472/268472 [==============================] - 314s 1ms/step - loss: 14.1113 - mean_absolute_error: 3.1752\n",
      "MAE: 3.1751532554626465    Time Taken: 2455.9027378559113 seconds\n",
      "--- Starting trial: run-20\n",
      "{'num_units': 32, 'dropout': 0.5, 'num_layers': 4}\n",
      "268472/268472 [==============================] - 321s 1ms/step - loss: 14.0940 - mean_absolute_error: 3.1547\n",
      "MAE: 3.154683828353882    Time Taken: 3624.537680387497 seconds\n",
      "--- Starting trial: run-21\n",
      "{'num_units': 8, 'dropout': 0.75, 'num_layers': 4}\n",
      "268472/268472 [==============================] - 329s 1ms/step - loss: 18.1709 - mean_absolute_error: 3.8770\n",
      "MAE: 3.8770172595977783    Time Taken: 4693.5349752902985 seconds\n",
      "--- Starting trial: run-22\n",
      "{'num_units': 16, 'dropout': 0.75, 'num_layers': 4}\n",
      "268472/268472 [==============================] - 331s 1ms/step - loss: 16.0334 - mean_absolute_error: 3.6061\n",
      "MAE: 3.6061103343963623    Time Taken: 2537.3515298366547 seconds\n",
      "--- Starting trial: run-23\n",
      "{'num_units': 24, 'dropout': 0.75, 'num_layers': 4}\n",
      "268472/268472 [==============================] - 323s 1ms/step - loss: 15.2731 - mean_absolute_error: 3.3906\n",
      "MAE: 3.3905529975891113    Time Taken: 4832.948200702667 seconds\n",
      "--- Starting trial: run-24\n",
      "{'num_units': 32, 'dropout': 0.75, 'num_layers': 4}\n",
      "268472/268472 [==============================] - 315s 1ms/step - loss: 15.0376 - mean_absolute_error: 3.4091\n",
      "MAE: 3.409092903137207    Time Taken: 4658.580439567566 seconds\n",
      "--- Starting trial: run-25\n",
      "{'num_units': 8, 'dropout': 0.25, 'num_layers': 6}\n"
     ]
    }
   ],
   "source": [
    "session_num = 18\n",
    "for num_layers in HP_NUM_LAYERS.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for num_units in HP_NUM_UNITS.domain.values:\n",
    "            if int(num_layers) == 2:\n",
    "                continue\n",
    "            if int(num_layers) == 4 and float(dropout_rate) == 0.25:\n",
    "                continue\n",
    "            if int(num_layers) == 4 and float(dropout_rate) == 0.50 and int(num_units)==8:\n",
    "                continue\n",
    "            hparams = {\n",
    "                HP_NUM_UNITS: num_units,\n",
    "                HP_DROPOUT: dropout_rate,\n",
    "                HP_NUM_LAYERS: num_layers,\n",
    "            }\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            run('logs/hparam_tuning/' + run_name, hparams)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
