{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ========================================\n",
        "#               LOAD DATA\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "\n",
        "df = pd.read_csv(\"/users/facsupport/asharma/Data/Preprocessed/tmp/ONE.csv\")\n",
        "# Keep \"interesting\" jobs (TODO - use strings instead)\n",
        "df = df[df['jobTitle'].isin([33,34,35,11,12,3,5,16,17])]\n",
        "\n",
        "#%%\n",
        "# ========================================\n",
        "#          SPLIT & PREP DATAFRAME\n",
        "# ========================================\n",
        "\n",
        "# Drop unnamed column (TODO - export csv without this in the first place)\n",
        "del df['Unnamed: 0']\n",
        "\n",
        "# Drop 90th day of facility data\n",
        "del df['f_89']\n",
        "\n",
        "inputs = df.drop(['t_89'], axis=1)\n",
        "labels = df.filter(['t_89'])\n",
        "\n",
        "# Weights to split data set\n",
        "TRAINING_WEIGHT = 0.7\n",
        "VALIDATION_WEIGHT = 0.2\n",
        "TEST_WEIGHT = 0.1\n",
        "\n",
        "n = len(df)\n",
        "weights_sum = TRAINING_WEIGHT + VALIDATION_WEIGHT + TEST_WEIGHT\n",
        "split1 = int(TRAINING_WEIGHT / weights_sum * n)\n",
        "split2 = int((TRAINING_WEIGHT + VALIDATION_WEIGHT) / weights_sum * n)\n",
        "\n",
        "train_inputs, train_labels = inputs[:split1], labels[:split1]\n",
        "val_inputs, val_labels = inputs[split1:split2], labels[split1:split2]\n",
        "test_inputs, test_labels = inputs[split2:], labels[split2:]\n",
        "\n",
        "#%%\n",
        "# ========================================\n",
        "#          DATAFRAME TO LGB DS\n",
        "# ========================================\n",
        "\n",
        "cats = ['jobTitle', 'providerId', 'payType', 'dayOfWeek']\n",
        "\n",
        "train_data = lgb.Dataset(train_inputs, label=train_labels, categorical_feature=cats)\n",
        "val_data = lgb.Dataset(val_inputs, label=val_labels, categorical_feature=cats)\n",
        "test_data = lgb.Dataset(test_inputs, label=test_labels, categorical_feature=cats)\n",
        "\n",
        "#%%\n",
        "# ========================================\n",
        "#            TRAIN WITH LGB\n",
        "# ========================================\n",
        "param = {\n",
        "  'num_leaves': 100,\n",
        "  'learning_rate': 0.1,\n",
        "  'metric': 'mse',\n",
        "}\n",
        "evals_result = {}\n",
        "bst = lgb.train(param, train_data, valid_sets=[val_data], evals_result=evals_result)"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}