{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from data_prep import initial_preprocess\n",
    "from window_generator import WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#                 SETTINGS\n",
    "# ========================================\n",
    "\n",
    "# Data input file\n",
    "RAW_DATA_PATH = '/users/facsupport/asharma/Data/pbj_full.csv'\n",
    "PREPROCESSED_DIR = '/users/facsupport/asharma/Data/prep/'\n",
    "ROWS_TO_READ = 50000\n",
    "\n",
    "# Weights to split data set\n",
    "TRAINING_WEIGHT = 0.7\n",
    "VALIDATION_WEIGHT = 0.2\n",
    "TEST_WEIGHT = 0.1\n",
    "\n",
    "# For model training\n",
    "MAX_EPOCHS = 20\n",
    "VERBOSE_TRAINING = 1\n",
    "\n",
    "# Window parameters\n",
    "INPUT_WIDTH = 7\n",
    "GAP_WIDTH = 0\n",
    "LABEL_WIDTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data from '/users/facsupport/asharma/Data/prep/pbj_nrows_50000_zeros_norm.csv'...\n",
      "Failed.\n",
      "Loading data...\n",
      "Filling missing shifts...\n",
      "Saving preprocessed data...\n",
      "Preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               PREPROCESSING\n",
    "# ========================================\n",
    "\n",
    "# Preprocess data\n",
    "df, info = initial_preprocess(\n",
    "    RAW_DATA_PATH, PREPROCESSED_DIR,\n",
    "    nrows=ROWS_TO_READ,\n",
    "    fill_missing_shifts=True,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Split data into training/validation/test sets\n",
    "n = len(df)\n",
    "weights_sum = TRAINING_WEIGHT + VALIDATION_WEIGHT + TEST_WEIGHT\n",
    "split1 = int(TRAINING_WEIGHT / weights_sum * n)\n",
    "split2 = int((TRAINING_WEIGHT + VALIDATION_WEIGHT) / weights_sum * n)\n",
    "train_df = df[:split1]\n",
    "val_df = df[split1:split2]\n",
    "test_df = df[split2:]\n",
    "\n",
    "# Create window generator\n",
    "window = WindowGenerator(\n",
    "    train_df, val_df, test_df,\n",
    "    INPUT_WIDTH, LABEL_WIDTH, GAP_WIDTH,\n",
    "    label_columns=['hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#                 MODELS\n",
    "# ========================================\n",
    "\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training dense model.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#                 TRAINING\n",
    "# ========================================\n",
    "\n",
    "def compile_and_fit(model, window, patience=3, verbose=0):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping],\n",
    "                      verbose=verbose)\n",
    "    return history\n",
    "\n",
    "print()\n",
    "print(\"Training dense model.\")\n",
    "history = compile_and_fit(dense, window, verbose=VERBOSE_TRAINING)\n",
    "\n",
    "print()\n",
    "print(\"Training LSTM model.\")\n",
    "history = compile_and_fit(lstm_model, window, verbose=VERBOSE_TRAINING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#                 EVALUATION\n",
    "# ========================================\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "\n",
    "print()\n",
    "print(\"Evaluating dense model.\")\n",
    "val_performance['Dense'] = dense.evaluate(window.val, verbose=VERBOSE_TRAINING)\n",
    "performance['Dense'] = dense.evaluate(window.test, verbose=0)\n",
    "\n",
    "print()\n",
    "print(\"Evaluating LSTM model.\")\n",
    "val_performance['LSTM'] = lstm_model.evaluate(window.val, verbose=VERBOSE_TRAINING)\n",
    "performance['LSTM'] = lstm_model.evaluate(window.test, verbose=0)\n",
    "\n",
    "print()\n",
    "print(\"Overall validation performance:\")\n",
    "for model_name, (loss, mea) in val_performance.items():\n",
    "    print(\"%s %.4f loss, %.4f mean abs error (%.4f hours)\" % ((model_name + \":\").ljust(17), loss, mea, mea * std['hours']) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
