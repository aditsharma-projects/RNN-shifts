{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# CONFIGURATION\n",
        "\n",
        "ROWS = 10 ** 5\n",
        "\n",
        "TRAIN_FILE = \"/export/storage_adgandhi/PBJhours_ML/Data/Intermediate/train_test_validation/training_set.csv\"\n",
        "VAL_FILE = \"/export/storage_adgandhi/PBJhours_ML/Data/Intermediate/train_test_validation/validation_set.csv\"\n",
        "TEST_FILE = \"/export/storage_adgandhi/PBJhours_ML/Data/Intermediate/train_test_validation/testing_set.csv\"\n",
        "\n",
        "types = {\n",
        "    \"prov_id\": np.int32,\n",
        "    \"employee_id\": np.int32,\n",
        "    \"job_title\": np.int32,\n",
        "    \"pay_type\": np.int32,\n",
        "    \"hours\": np.double,\n",
        "    \"day_of_week\": np.int32,\n",
        "}\n",
        "\n",
        "for i in range(1, 31):\n",
        "    types[f\"hours_l{i}\"] = np.double\n",
        "    types[f\"employees_l{i}\"] = np.int32\n",
        "\n",
        "for i in range(7):\n",
        "    types[f\"week_perc{i}\"] = np.double\n",
        "\n",
        "cats = ['job_title', 'prov_id', 'pay_type', 'day_of_week']"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# LOAD DATA\n",
        "train = pd.read_csv(TRAIN_FILE, parse_dates=[\"date\"], nrows=ROWS)\n",
        "val = pd.read_csv(VAL_FILE, parse_dates=[\"date\"], nrows=ROWS //2)\n",
        "test = pd.read_csv(TEST_FILE, parse_dates=[\"date\"], nrows=ROWS //1000)\n",
        "\n",
        "stds = {}\n",
        "\n",
        "for df in [train, val, test]:\n",
        "    df.dropna(inplace=True) # Drop all rows with N/A values\n",
        "    for col, t in types.items(): # Cast remaining rows to appropriate type\n",
        "        df[col] = df[col].astype(t)\n",
        "\n",
        "for col_name in [\"hours\"] + [f\"hours_l{i}\" for i in range(1, 31)]:\n",
        "    mean = train[col_name].mean()\n",
        "    std = train[col_name].std()\n",
        "    stds[col_name] = std\n",
        "    for df in [train, val, test]:\n",
        "        df[col_name] = (df[col_name] - mean) / std\n",
        "\n",
        "# todo - choose columns based on class constants\n",
        "train_inputs, train_labels = train.drop(['employee_id','date','hours', 'week'], axis=1).filter(types.keys()), train.filter(['hours'])\n",
        "val_inputs, val_labels = val.drop(['employee_id','date','hours', 'week'], axis=1).filter(types.keys()), val.filter(['hours'])\n",
        "test_inputs, test_labels = test.drop(['employee_id','date','hours', 'week'], axis=1).filter(types.keys()), test.filter(['hours'])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# DEFINE MODELS\n",
        "\n",
        "dense = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])\n",
        "\n",
        "lstm = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(units=64),\n",
        "    tf.keras.layers.Dense(units=1),\n",
        "])"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# TRAIN MODELS\n",
        "\n",
        "print('\\nTraining dense model.\\n')\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                patience=2,\n",
        "                                                mode='min')\n",
        "dense.compile(loss=tf.losses.MeanSquaredError(),\n",
        "            optimizer=tf.optimizers.Adam(clipvalue=0.5),\n",
        "            metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "history = dense.fit(train_inputs, train_labels, epochs=20,\n",
        "            validation_data=(val_inputs, val_labels),\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=1)\n",
        "\n",
        "print('\\nTraining LSTM.\\n')\n",
        "lstm.compile(loss=tf.losses.MeanSquaredError(),\n",
        "            optimizer=tf.optimizers.Adam(clipvalue=0.5),\n",
        "            metrics=[tf.metrics.MeanAbsoluteError()])\n",
        "\n",
        "def lstm_reshape(df):\n",
        "    df = df.to_numpy()\n",
        "    return df.reshape((df.shape[0], 1, df.shape[1]))\n",
        "\n",
        "history = lstm.fit(lstm_reshape(train_inputs), lstm_reshape(train_labels), epochs=20,\n",
        "            validation_data=(lstm_reshape(val_inputs), lstm_reshape(val_labels)),\n",
        "            callbacks=[early_stopping],\n",
        "            verbose=1)\n",
        "\n",
        "print('\\nHours STD: ' + str(stds['hours']))"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}