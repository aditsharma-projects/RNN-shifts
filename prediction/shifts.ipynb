{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from data_prep import initial_preprocess\n",
    "from window_generator import WindowGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#                 SETTINGS\n",
    "# ========================================\n",
    "\n",
    "# Data input file\n",
    "RAW_DATA_PATH = '/users/facsupport/asharma/Data/pbj_full.csv'\n",
    "PREPROCESSED_DIR = '/users/facsupport/asharma/Data/prep/'\n",
    "ROWS_TO_READ = 50000\n",
    "\n",
    "# Weights to split data set\n",
    "TRAINING_WEIGHT = 0.7\n",
    "VALIDATION_WEIGHT = 0.2\n",
    "TEST_WEIGHT = 0.1\n",
    "\n",
    "# For model training\n",
    "MAX_EPOCHS = 20\n",
    "VERBOSE_TRAINING = 1\n",
    "\n",
    "# Window parameters\n",
    "INPUT_WIDTH = 7\n",
    "GAP_WIDTH = 0\n",
    "LABEL_WIDTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data from '/users/facsupport/asharma/Data/prep/pbj_nrows_50000_zeros_norm.csv'...\n",
      "Failed.\n",
      "Loading data...\n",
      "Filling missing shifts...\n",
      "Saving preprocessed data...\n",
      "Preprocessing finished.\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#               PREPROCESSING\n",
    "# ========================================\n",
    "\n",
    "# Preprocess data\n",
    "df, info = initial_preprocess(\n",
    "    RAW_DATA_PATH, PREPROCESSED_DIR,\n",
    "    nrows=ROWS_TO_READ,\n",
    "    fill_missing_shifts=True,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Split data into training/validation/test sets\n",
    "n = len(df)\n",
    "weights_sum = TRAINING_WEIGHT + VALIDATION_WEIGHT + TEST_WEIGHT\n",
    "split1 = int(TRAINING_WEIGHT / weights_sum * n)\n",
    "split2 = int((TRAINING_WEIGHT + VALIDATION_WEIGHT) / weights_sum * n)\n",
    "train_df = df[:split1]\n",
    "val_df = df[split1:split2]\n",
    "test_df = df[split2:]\n",
    "\n",
    "# Create window generator\n",
    "window = WindowGenerator(\n",
    "    train_df, val_df, test_df,\n",
    "    INPUT_WIDTH, LABEL_WIDTH, GAP_WIDTH,\n",
    "    label_columns=['hours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#                 MODELS\n",
    "# ========================================\n",
    "\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])\n",
    "\n",
    "dense = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=64, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training dense model.\n",
      "Epoch 1/20\n",
      "1935/1935 [==============================] - 50s 26ms/step - loss: 0.9821 - mean_absolute_error: 0.9170 - val_loss: 0.9220 - val_mean_absolute_error: 0.9026\n",
      "Epoch 2/20\n",
      "1935/1935 [==============================] - 55s 28ms/step - loss: 0.9740 - mean_absolute_error: 0.9152 - val_loss: 0.9177 - val_mean_absolute_error: 0.8984\n",
      "Epoch 3/20\n",
      "1935/1935 [==============================] - 52s 27ms/step - loss: 0.9724 - mean_absolute_error: 0.9141 - val_loss: 0.9168 - val_mean_absolute_error: 0.8972\n",
      "Epoch 4/20\n",
      "1935/1935 [==============================] - 56s 29ms/step - loss: 0.9719 - mean_absolute_error: 0.9135 - val_loss: 0.9176 - val_mean_absolute_error: 0.8982\n",
      "Epoch 5/20\n",
      "1935/1935 [==============================] - 52s 27ms/step - loss: 0.9718 - mean_absolute_error: 0.9133 - val_loss: 0.9165 - val_mean_absolute_error: 0.8963\n",
      "Epoch 6/20\n",
      "1935/1935 [==============================] - 52s 27ms/step - loss: 0.9714 - mean_absolute_error: 0.9129 - val_loss: 0.9161 - val_mean_absolute_error: 0.8952\n",
      "Epoch 7/20\n",
      "1935/1935 [==============================] - 52s 27ms/step - loss: 0.9707 - mean_absolute_error: 0.9125 - val_loss: 0.9159 - val_mean_absolute_error: 0.8950\n",
      "Epoch 8/20\n",
      "1935/1935 [==============================] - 53s 27ms/step - loss: 0.9705 - mean_absolute_error: 0.9123 - val_loss: 0.9157 - val_mean_absolute_error: 0.8944\n",
      "Epoch 9/20\n",
      "1935/1935 [==============================] - 53s 27ms/step - loss: 0.9704 - mean_absolute_error: 0.9122 - val_loss: 0.9155 - val_mean_absolute_error: 0.8939\n",
      "Epoch 10/20\n",
      "1935/1935 [==============================] - 53s 28ms/step - loss: 0.9701 - mean_absolute_error: 0.9119 - val_loss: 0.9153 - val_mean_absolute_error: 0.8935\n",
      "Epoch 11/20\n",
      "1935/1935 [==============================] - 53s 27ms/step - loss: 0.9699 - mean_absolute_error: 0.9117 - val_loss: 0.9153 - val_mean_absolute_error: 0.8933\n",
      "Epoch 12/20\n",
      "1935/1935 [==============================] - 52s 27ms/step - loss: 0.9698 - mean_absolute_error: 0.9116 - val_loss: 0.9153 - val_mean_absolute_error: 0.8928\n",
      "Epoch 13/20\n",
      "1935/1935 [==============================] - 54s 28ms/step - loss: 0.9697 - mean_absolute_error: 0.9114 - val_loss: 0.9171 - val_mean_absolute_error: 0.8973\n",
      "Epoch 14/20\n",
      "1935/1935 [==============================] - 53s 27ms/step - loss: 0.9709 - mean_absolute_error: 0.9126 - val_loss: 0.9153 - val_mean_absolute_error: 0.8935\n",
      "Epoch 15/20\n",
      "1935/1935 [==============================] - 57s 30ms/step - loss: 0.9698 - mean_absolute_error: 0.9113 - val_loss: 0.9151 - val_mean_absolute_error: 0.8930\n",
      "Epoch 16/20\n",
      "1935/1935 [==============================] - 53s 28ms/step - loss: 0.9697 - mean_absolute_error: 0.9111 - val_loss: 0.9149 - val_mean_absolute_error: 0.8927\n",
      "Epoch 17/20\n",
      "1935/1935 [==============================] - 53s 28ms/step - loss: 0.9695 - mean_absolute_error: 0.9108 - val_loss: 0.9148 - val_mean_absolute_error: 0.8925\n",
      "Epoch 18/20\n",
      "1935/1935 [==============================] - 54s 28ms/step - loss: 0.9693 - mean_absolute_error: 0.9106 - val_loss: 0.9146 - val_mean_absolute_error: 0.8922\n",
      "Epoch 19/20\n",
      "1935/1935 [==============================] - 56s 29ms/step - loss: 0.9692 - mean_absolute_error: 0.9104 - val_loss: 0.9144 - val_mean_absolute_error: 0.8919\n",
      "Epoch 20/20\n",
      "1935/1935 [==============================] - 55s 29ms/step - loss: 0.9689 - mean_absolute_error: 0.9102 - val_loss: 0.9142 - val_mean_absolute_error: 0.8916\n",
      "\n",
      "Training LSTM model.\n",
      "Epoch 1/20\n",
      "1935/1935 [==============================] - 63s 32ms/step - loss: 0.8649 - mean_absolute_error: 0.8213 - val_loss: 0.8228 - val_mean_absolute_error: 0.8164\n",
      "Epoch 2/20\n",
      "1935/1935 [==============================] - 60s 31ms/step - loss: 0.8157 - mean_absolute_error: 0.7768 - val_loss: 0.8169 - val_mean_absolute_error: 0.8095\n",
      "Epoch 3/20\n",
      "1935/1935 [==============================] - 60s 31ms/step - loss: 0.8069 - mean_absolute_error: 0.7699 - val_loss: 0.8090 - val_mean_absolute_error: 0.8036\n",
      "Epoch 4/20\n",
      "1935/1935 [==============================] - 61s 31ms/step - loss: 0.7971 - mean_absolute_error: 0.7614 - val_loss: 0.7986 - val_mean_absolute_error: 0.7932\n",
      "Epoch 5/20\n",
      "1935/1935 [==============================] - 61s 31ms/step - loss: 0.7903 - mean_absolute_error: 0.7542 - val_loss: 0.7949 - val_mean_absolute_error: 0.7888\n",
      "Epoch 6/20\n",
      "1935/1935 [==============================] - 62s 32ms/step - loss: 0.7870 - mean_absolute_error: 0.7507 - val_loss: 0.7933 - val_mean_absolute_error: 0.7862\n",
      "Epoch 7/20\n",
      "1935/1935 [==============================] - 62s 32ms/step - loss: 0.7848 - mean_absolute_error: 0.7486 - val_loss: 0.7923 - val_mean_absolute_error: 0.7843\n",
      "Epoch 8/20\n",
      "1935/1935 [==============================] - 62s 32ms/step - loss: 0.7829 - mean_absolute_error: 0.7472 - val_loss: 0.7915 - val_mean_absolute_error: 0.7825\n",
      "Epoch 9/20\n",
      "1935/1935 [==============================] - 61s 32ms/step - loss: 0.7814 - mean_absolute_error: 0.7460 - val_loss: 0.7907 - val_mean_absolute_error: 0.7807\n",
      "Epoch 10/20\n",
      "1935/1935 [==============================] - 62s 32ms/step - loss: 0.7800 - mean_absolute_error: 0.7449 - val_loss: 0.7900 - val_mean_absolute_error: 0.7790\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "#                 TRAINING\n",
    "# ========================================\n",
    "\n",
    "def compile_and_fit(model, window, patience=3, verbose=0):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                    patience=patience,\n",
    "                                                    mode='min')\n",
    "    model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "                optimizer=tf.optimizers.Adam(),\n",
    "                metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    history = model.fit(window.train, epochs=MAX_EPOCHS,\n",
    "                      validation_data=window.val,\n",
    "                      callbacks=[early_stopping],\n",
    "                      verbose=verbose)\n",
    "    return history\n",
    "\n",
    "print()\n",
    "print(\"Training dense model.\")\n",
    "history = compile_and_fit(dense, window, verbose=VERBOSE_TRAINING)\n",
    "\n",
    "print()\n",
    "print(\"Training LSTM model.\")\n",
    "history = compile_and_fit(lstm_model, window, verbose=VERBOSE_TRAINING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "#                 EVALUATION\n",
    "# ========================================\n",
    "\n",
    "val_performance = {}\n",
    "performance = {}\n",
    "\n",
    "print()\n",
    "print(\"Evaluating dense model.\")\n",
    "val_performance['Dense'] = dense.evaluate(window.val, verbose=VERBOSE_TRAINING)\n",
    "performance['Dense'] = dense.evaluate(window.test, verbose=0)\n",
    "\n",
    "print()\n",
    "print(\"Evaluating LSTM model.\")\n",
    "val_performance['LSTM'] = lstm_model.evaluate(window.val, verbose=VERBOSE_TRAINING)\n",
    "performance['LSTM'] = lstm_model.evaluate(window.test, verbose=0)\n",
    "\n",
    "print()\n",
    "print(\"Overall validation performance:\")\n",
    "for model_name, (loss, mea) in val_performance.items():\n",
    "    print(\"%s %.4f loss, %.4f mean abs error (%.4f hours)\" % ((model_name + \":\").ljust(17), loss, mea, mea * std['hours']) )"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
